{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n# ms-python.python added\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), 'source'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["import numpy as np\n","\n","np.random.seed(42)\n","\n","train_set = np.load('../data/train_set.npy', allow_pickle=True)\n","test_set = np.load('../data/test_set.npy', allow_pickle=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["train_set_len = len(train_set)\n","data_frame_len = len(train_set[0][0])\n","data_channel_len = len(train_set[0][0][0])\n","x_train = np.empty((train_set_len, data_frame_len, data_channel_len))\n","y_train = np.empty((train_set_len))\n","for idx in range(train_set_len):\n","    x_train[idx] = train_set[idx, 0]\n","    y_train[idx] = train_set[idx, 1]\n","\n","xn_0 = x_train\n","\n","test_set_len = len(test_set)\n","x_test = np.empty((test_set_len, data_frame_len, data_channel_len))\n","y_test = np.empty((test_set_len))\n","for idx in range(test_set_len):\n","    x_test[idx] = test_set[idx, 0]\n","    y_test[idx] = test_set[idx, 1]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from sklearn.base import TransformerMixin\n","import numpy as np\n","import scipy.stats as stats\n","\n","# roor mean square\n","def rms(x):\n","  x = np.array(x)\n","  return np.sqrt(np.mean(np.square(x)))\n","# square root amplitude\n","def sra(x):\n","  x = np.array(x)\n","  return np.mean(np.sqrt(np.absolute(x)))**2\n","# peak to peak value\n","def ppv(x):\n","  x = np.array(x)\n","  return np.max(x)-np.min(x)\n","# crest factor\n","def cf(x):\n","  x = np.array(x)\n","  return np.max(np.absolute(x))/rms(x)\n","# impact factor\n","def ifa(x):\n","  x = np.array(x)\n","  return np.max(np.absolute(x))/np.mean(np.absolute(x))\n","# margin factor\n","def mf(x):\n","  x = np.array(x)\n","  return np.max(np.absolute(x))/sra(x)\n","# shape factor\n","def sf(x):\n","  x = np.array(x)\n","  return rms(x)/np.mean(np.absolute(x))\n","# kurtosis factor\n","def kf(x):\n","  x = np.array(x)\n","  return stats.kurtosis(x)/(np.mean(x**2)**2)\n","\n","class StatisticalTime(TransformerMixin):\n","  def __init__(self):\n","    pass\n","  def fit(self, X, y=None):\n","    return self\n","  def transform(self, X, y=None):\n","    if X.shape[2] == 1:\n","      return np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,0]])\n","    de = np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,0]])\n","    fe = np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,1]])\n","    return np.concatenate((de,fe),axis=1)\n","  \n","class StatisticalFrequency(TransformerMixin):\n","  def __init__(self):\n","    pass\n","  def fit(self, X, y=None):\n","    return self\n","  def transform(self, X, y=None):\n","    if X.shape[2] == 1:\n","      sig = []\n","      for x in X[:,:,0]:\n","        fx = np.absolute(np.fft.fft(x))\n","        fc = np.mean(fx)\n","        sig.append([fc, rms(fx), rms(fx-fc)])\n","      return np.array(sig)\n","    de = []\n","    for x in X[:,:,0]:\n","      fx = np.absolute(np.fft.fft(x))\n","      fc = np.mean(fx)\n","      de.append([fc, rms(fx), rms(fx-fc)])\n","    de = np.array(de)\n","    fe = []\n","    for x in X[:,:,1]:\n","      fx = np.absolute(np.fft.fft(x))\n","      fc = np.mean(fx)\n","      fe.append([fc, rms(fx), rms(fx-fc)])\n","    fe = np.array(fe)\n","    return np.concatenate((de,fe),axis=1)\n","\n","class Statistical(TransformerMixin):\n","  def __init__(self):\n","    pass\n","  def fit(self, X, y=None):\n","    return self\n","  def transform(self, X, y=None):\n","    st = StatisticalTime()\n","    stfeats = st.transform(X)\n","    sf = StatisticalFrequency()\n","    sffeats = sf.transform(X)\n","    return np.concatenate((stfeats,sffeats),axis=1)\n","   \n","import pywt\n","class WaveletPackage(TransformerMixin):\n","  def __init__(self):\n","    pass\n","  def fit(self, X, y=None):\n","    return self\n","  def transform(self, X, y=None):\n","    def Energy(coeffs, k):\n","      return np.sqrt(np.sum(np.array(coeffs[-k]) ** 2)) / len(coeffs[-k])\n","    def getEnergy(wp):\n","      coefs = np.asarray([n.data for n in wp.get_leaf_nodes(True)])\n","      return np.asarray([Energy(coefs,i) for i in range(2**wp.maxlevel)])\n","    if X.shape[2] == 1:\n","      return np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', mode='symmetric', maxlevel=4)) for x in X[:,:,0]])\n","    de = np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', mode='symmetric', maxlevel=4)) for x in X[:,:,0]])\n","    fe = np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', mode='symmetric', maxlevel=4)) for x in X[:,:,1]])\n","    return np.concatenate((de,fe),axis=1)\n","\n","class Heterogeneous(TransformerMixin):\n","  def __init__(self):\n","    pass\n","  def fit(self, X, y=None):\n","    return self\n","  def transform(self, X, y=None):\n","    st = StatisticalTime()\n","    stfeats = st.transform(X)\n","    sf = StatisticalFrequency()\n","    sffeats = sf.transform(X)\n","    wp = WaveletPackage()\n","    wpfeats = wp.transform(X)\n","    return np.concatenate((stfeats,sffeats,wpfeats),axis=1)\n","\n","from keras import backend as K\n","def f1_score_macro(y_true,y_pred):\n","    def recall(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","    def precision(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from keras import layers\n","from keras import Input\n","from keras.models import Model\n","from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n","from keras.utils import to_categorical\n","\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.utils import shuffle\n","class ANNConv1D(BaseEstimator, ClassifierMixin):\n","  def __init__(self, filters=16, kernel_size=22, shape=xn_0.shape):\n","    self.shape = shape\n","    self.filters = filters\n","    self.kernel_size = kernel_size\n","\n","  def fit(self, X, y=None):\n","    y_cat = to_categorical(y)\n","    signal_input = Input(shape=(self.shape[1],self.shape[-1]), dtype='float32', name='signal')\n","    x = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', name='conv1d_1')(signal_input)\n","    x = layers.MaxPooling1D(self.kernel_size, name='max_pooling1d_1')(x)\n","    x = layers.Flatten(name='flatten')(x)\n","    condition_output = layers.Dense(7,activation='softmax',name='condition')(x)\n","    self.model = Model(signal_input, condition_output) \n","    self.model.compile(optimizer='rmsprop',\n","                       loss='mean_squared_error', \n","                       metrics=['accuracy',f1_score_macro])\n","      \n","    self.history = self.model.fit(X ,y_cat, epochs=1, \n","                                  validation_split=0.2,\n","                                  callbacks=[EarlyStopping(patience=3),\n","                                             ReduceLROnPlateau()],\n","                                  verbose=1)\n","    return self\n","\n","  def predict(self, X, y=None):\n","    return np.argmax(self.model.predict(X), axis=1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","\n","pipeline = Pipeline([\n","        ('std_scaler', StandardScaler()),\n","    ])\n","\n","param_grid = [\n","        {'filters': [32, 64, 128], 'kernel_size': [5, 7, 10, 37]},\n","    ]\n","\n","conv1d = ANNConv1D(shape=xn_0.shape)\n","grid_search = GridSearchCV(conv1d, param_grid, cv=5, scoring='accuracy', verbose=2)\n","grid_search.fit(x_train, y_train)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["import itertools\n","from sklearn.metrics import confusion_matrix\n","from matplotlib import pyplot as plt\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Greys):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    #plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Actual label')\n","    plt.xlabel('Predicted label')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","knn = Pipeline([('FeatureExtraction', Heterogeneous()),\n","                ('scaler', StandardScaler()),\n","                ('KNN', KNeighborsClassifier())])\n","\n","param_dist = {\"n_estimators\": [10, 20],\n","              \"max_features\": [4, 8, None]}\n","rf = Pipeline([('FeatureExtraction', Heterogeneous()),\n","               ('scaler', StandardScaler()),\n","               ('RF', GridSearchCV(RandomForestClassifier(),\n","                                   param_grid=param_dist))])\n","\n","conv1d = ANNConv1D(shape=xn_0.shape, **grid_search.best_params_)\n","clfs = [(\"K-NNeighbors\", knn),\n","        (\"RandomForest\", rf),\n","        (\"ANN-Conv1d\", conv1d)]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from sklearn.metrics import f1_score, accuracy_score\n","\n","class_names = ['Idle', 'Signal 1', 'Signal 2', 'Signal 3', 'Signal 4', 'Signal 5','Signal 6']\n","figprop = np.linspace(1, 0.5, 25)\n","tam = len(class_names) * figprop[len(class_names)]\n","\n","\n","results = {}\n","models = {}\n","genconfmat = True\n","results['st'] = {}\n","models['st'] = {}\n","\n","for clfname, model in clfs:\n","    print(clfname, end=\":\\t\")\n","    if not clfname in results['st']:\n","        results['st'][clfname] = []\n","    history = model.fit(x_train ,y_train)\n","    y_pred = model.predict(x_test)\n","    results['st'][clfname].append([accuracy_score(y_test,y_pred),f1_score(y_test,y_pred,average='macro')])\n","    print(results['st'][clfname][-1])\n","    if genconfmat:\n","        cnf_matrix = confusion_matrix(y_test, y_pred)\n","        print(cnf_matrix)\n","        plt.figure(figsize=(tam,tam))\n","        plot_confusion_matrix(cnf_matrix, classes=class_names, title=clfname+' - ST ', normalize=False)\n","        #plt.savefig('cnfmatrix_st'+clfname+str(fold)+'round'+str(j)+'.png')\n","        plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["for evaluation in results.keys():\n","  print(\"\\n\"+30*\"#\"+\"\\n\"+evaluation+\"\\n\"+30*\"#\")\n","  for clfname,model in clfs:\n","    print(\"\\n\\t\"+clfname+\" Results\\nAccuracy\\tF1-Score\")\n","    for i,r in enumerate(results[evaluation][clfname]):\n","      print(\"{}\\t\".format(i+1),end=\"\")\n","      print(r)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}